{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bee8d307-1818-4d3e-86c7-8d3873393b5b",
   "metadata": {},
   "source": [
    "# Part 3: Peer-to-peer Message Behaviour Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a89661-48f9-433d-9ac3-00f94b220e76",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775c58e9-c1bb-471e-8d7e-5ebcf36c750d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Install Python packages (pip only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c433636-63e8-45ac-91ab-df4598e50d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ndlib in /Users/zhukai/anaconda3/lib/python3.11/site-packages (5.1.1)\n",
      "Requirement already satisfied: netdispatch in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from ndlib) (0.1.0)\n",
      "Requirement already satisfied: python-igraph in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from ndlib) (0.11.4)\n",
      "Requirement already satisfied: numpy in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from ndlib) (1.24.3)\n",
      "Requirement already satisfied: networkx in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from ndlib) (3.1)\n",
      "Requirement already satisfied: dynetx in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from ndlib) (0.3.2)\n",
      "Requirement already satisfied: scipy in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from ndlib) (1.11.1)\n",
      "Requirement already satisfied: bokeh in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from ndlib) (3.2.1)\n",
      "Requirement already satisfied: future in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from ndlib) (0.18.3)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from bokeh->ndlib) (3.1.2)\n",
      "Requirement already satisfied: contourpy>=1 in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from bokeh->ndlib) (1.0.5)\n",
      "Requirement already satisfied: packaging>=16.8 in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from bokeh->ndlib) (23.1)\n",
      "Requirement already satisfied: pandas>=1.2 in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from bokeh->ndlib) (2.0.3)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from bokeh->ndlib) (9.4.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from bokeh->ndlib) (6.0)\n",
      "Requirement already satisfied: tornado>=5.1 in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from bokeh->ndlib) (6.3.2)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from bokeh->ndlib) (2022.9.0)\n",
      "Requirement already satisfied: tqdm in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from dynetx->ndlib) (4.65.0)\n",
      "Requirement already satisfied: decorator in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from dynetx->ndlib) (5.1.1)\n",
      "Requirement already satisfied: igraph==0.11.4 in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from python-igraph->ndlib) (0.11.4)\n",
      "Requirement already satisfied: texttable>=1.6.2 in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from igraph==0.11.4->python-igraph->ndlib) (1.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from Jinja2>=2.9->bokeh->ndlib) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from pandas>=1.2->bokeh->ndlib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from pandas>=1.2->bokeh->ndlib) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from pandas>=1.2->bokeh->ndlib) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/zhukai/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.2->bokeh->ndlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#e.g., %pip install some-package\n",
    "%pip install ndlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a98e79-7408-4b7e-9937-f0611b21dc21",
   "metadata": {},
   "source": [
    "### Import Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02b645ed-b469-45e6-ba5b-1c70e7efd7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#e.g., import some-package\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import operator\n",
    "import random\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ndlib.models.ModelConfig as mc\n",
    "import ndlib.models.epidemics as ep\n",
    "import ndlib.models.CompositeModel as gc\n",
    "import ndlib.models.compartments as cs\n",
    "from ndlib.utils import multi_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e292c7-df21-4fe9-b720-c21acdd2ceb3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db29460-d751-47b9-a597-7f466a9e7f8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 1 of 2\n",
    "\n",
    "Examine the file \"p2p_msg_cmt224.csv\" which represents messaging behaviour between users on a messaging platform. Each row has four columns, representing a single event where a person (person_a) messaged another person (person_b) on some date (date) at some time of day (time). From this, answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f77652a-85fa-4fe6-b7e6-d95827082ca2",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Q1. Build a suitable network to represent social connections based on the messaging behaviour that took place in the first 28 days. In doing so, assume that one or more messages from one person to another represents a mutual underlying social connection (i.e., regardless of whether person_a messaged person_b, person_b messaged person_a, or both at some point). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a1fae4d-a6b8-4c71-aaba-1dfaff94252c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6507, 1146)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE:\n",
    "#read the .csv file to a pandas dataframe\n",
    "df = pd.read_csv(\"p2p_msg_cmt224.csv\")\n",
    "\n",
    "#change the type of date from str to datetime\n",
    "df['date'] = pd.to_datetime(df['date'],dayfirst=True)\n",
    "\n",
    "#get the earlies date in the dataset and add 28 days\n",
    "first_28_days = df['date'].min() + dt.timedelta(days=28)\n",
    "\n",
    "#filter the data to create a subset\n",
    "df_first_28_days = df.query(\"date < @first_28_days\").copy()\n",
    "\n",
    "#build an undirected graph from the data\n",
    "G_1st_28_days = nx.from_pandas_edgelist(df_first_28_days,\n",
    "                                        source='person_a',\n",
    "                                        target='person_b',\n",
    "                                        create_using=nx.Graph())\n",
    "\n",
    "G_1st_28_days.number_of_edges(),G_1st_28_days.number_of_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90233e71",
   "metadata": {},
   "source": [
    "ANSWER: Based on the requirement, an undirected graph was built.\n",
    "- Explanation: \n",
    "    - The data were load into a pandas dataframe as it is more convenient to include the messaging behaviour only happened in the first 28 days using filter.\n",
    "    - An undirected graph was created where the source is person_a and target is person_b.\n",
    "- Justification:\n",
    "    - An undirected graph captures the essence of social connections inferred from messaging behaviour, irrespective of the direction of messages exchanged between individuals, which is more suitable than directed graph in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a76d52-6471-4695-826c-788e3078fab9",
   "metadata": {},
   "source": [
    "##### Q2. Using the largest connected component of the network constructed in Task 1, Q1. What is the mean, median and the standard deviation of the differences between the maximum degree of separation of each individual and the average distance between the individual and all others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1808c52-538f-4461-b8be-5adc186a3592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean value is 2.24, the median value is 2.23, the standard deviation value is 0.4\n"
     ]
    }
   ],
   "source": [
    "#CODE:\n",
    "#Extract the connected components\n",
    "Cc = nx.connected_components(G_1st_28_days)\n",
    "#Extract the largest connected component\n",
    "Lcc = sorted(Cc,key=len,reverse=True)[0]\n",
    "#Create a subgraph for the largest connected component in first 28 days network\n",
    "G_1st_28_days_lcc = G_1st_28_days.subgraph(Lcc)\n",
    "\n",
    "#Calculate the eccentricity => The eccentricity of a node v is the maximum distance from v to all other nodes in G.\n",
    "eccentricity = nx.eccentricity(G_1st_28_days_lcc)\n",
    "\n",
    "#Find the every possible shortest path length for every node\n",
    "list_of_shortest_path_length_individual = list(nx.shortest_path_length(G_1st_28_days_lcc))\n",
    "\n",
    "#Calculate the average shortest path length, note the denominator is the length - 1 \n",
    "#because the previous result contains the node itself\n",
    "average_distance_individual = [(u,(sum(v.values()) / (len(v.values())-1))) for u,v in list_of_shortest_path_length_individual]\n",
    "\n",
    "#turn data to pandas dataframe\n",
    "df_average_distance_individual = pd.DataFrame(average_distance_individual)\\\n",
    ".rename(columns={0:'node',1:'average_distance'})\n",
    "\n",
    "#turn data to pandas dataframe\n",
    "df_eccentricity = pd.DataFrame(eccentricity,index=['eccentricity']).T.reset_index()\\\n",
    ".rename(columns={\"index\":\"node\"})\n",
    "\n",
    "#merge two dataframes\n",
    "df_result = df_eccentricity.merge(df_average_distance_individual,on=['node'])\n",
    "\n",
    "#calculate the difference\n",
    "df_result['difference'] = df_result[\"eccentricity\"] - df_result[\"average_distance\"]\n",
    "\n",
    "#print the results\n",
    "print(\"The mean value is {0}, the median value is {1}, the standard deviation value is {2}\".format(round(df_result['difference'].describe()['mean'],2),\n",
    "round(df_result['difference'].describe()['50%'],2),\n",
    "round(df_result['difference'].describe()['std'],2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6900da78",
   "metadata": {},
   "source": [
    "ANSWER: The mean, median and standard deviation of the differences between eccentricity and average distance are 2.24, 2.23, and 0.4 respectively.\n",
    "- Explanation:\n",
    "    - The largest connected component was extracted from previous network.\n",
    "    - Eccentricity was calculated for the subgraph.\n",
    "    - List of shortest path length for each node was extracted, and the average distance was then computed at individual level.\n",
    "    - Results were stored in pandas dataframes for calculating the mean,median and std value.\n",
    "- Justification:\n",
    "    - Eccentricity of a node represents the maximum degree of separation of each individual and all others, which directly answers the question.\n",
    "    - Average distance is the sum of shortest_path_length divided by the count of nodes - 1 since results include node itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a0743d-26e7-48b8-9f54-569ce6818ea9",
   "metadata": {},
   "source": [
    "##### Q3. Build another suitable network to represent social connections based on ALL message behaviour in the dataset. In doing so, assume that one or messages from one person to another represents a MUTUAL underlying social connection (i.e., regardless of whether person_a messaged person_b, person_b messaged person_a, or both at some point).Can the social phenomenon, ‚ÄòTriadic Closure‚Äô, be supported for the common nodes that exist in both the network created from behaviour for the first 28 days (i.e., from Task 1, Q1) and the network built from all message behaviour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5df320c0-3d4f-4217-a8eb-49263693d457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitivity for graph(first 28 days): 0.05\n",
      "Transitivity for graph(entire network with common nodes): 0.07\n"
     ]
    }
   ],
   "source": [
    "#CODE:\n",
    "#Create an undirected network based on all message behaviour\n",
    "G_all = nx.from_pandas_edgelist(df,\n",
    "                                source='person_a',\n",
    "                                target='person_b',\n",
    "                                create_using=nx.Graph())\n",
    "\n",
    "#Calculate the transitivity for each graph\n",
    "print((\"Transitivity for graph(first 28 days): {0}\").format(round(nx.transitivity(G_1st_28_days),2)))\n",
    "print((\"Transitivity for graph(entire network with common nodes): {0}\").format(round(nx.transitivity(G_all.subgraph(G_1st_28_days.nodes())),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b282266",
   "metadata": {},
   "source": [
    "ANSWER: The difference of two computed transitivity is 0.02, indicates that triadic closure can be supported for the common nodes over time.\n",
    "- Explanation: \n",
    "    - A new undirected graph was created based on all message behaviour where source is person_a and target is person_b. \n",
    "    - Transitivity was calculated for two networks based on the common nodes.\n",
    "- Justification: \n",
    "    - Undirected graph can represent mutual social connection as direction is ignored.\n",
    "    - Transitivity measures the social phenomenon 'triadic closure'. It computes the fraction of all possible triangles presented in a graph. \n",
    "    - One may consider calculating 16 possible types of triads, but it is more relevant for directed graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c69305-9297-4f3f-8248-537c45bb605e",
   "metadata": {},
   "source": [
    "##### Q4. What hypothetical, non-existent edges would need to be added to the network representing all message behaviour (i.e., from Task 1, Q3) such that a message could pass along a path from any node to any other? In doing so, aim to minimise the number of edges that would be needed as well as the longest shortest path in the network as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b807bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Components need to be connected with the largest connected component(LCC) are: [{229, 230}, {1258, 10}, {1192, 1530}, {1797, 1798}, {1812, 1813}]\n",
      "The diameter of the LCC is 8.\n",
      "The radius of the LCC is 4.\n",
      "Candidate nodes in LCC can be used for adding edges with are [32, 3, 105, 308, 456, 719, 1713].\n",
      "Is it true that the network is connected?: True.\n",
      "The diameter of the whole graph is 8.\n",
      "The radius of the whole graph is 4.\n"
     ]
    }
   ],
   "source": [
    "#CODE\n",
    "#copy the network\n",
    "G_all_copy = G_all.copy()\n",
    "#find the components need to be connected\n",
    "print(\"Components need to be connected with the largest connected component(LCC) are:\", list(nx.connected_components(G_all_copy))[1:])\n",
    "\n",
    "#Create a largest connected component\n",
    "Cc_all = nx.connected_components(G_all_copy)\n",
    "Lcc_all = sorted(Cc_all,key=len,reverse=True)[0]\n",
    "G_lcc_all = G_all.subgraph(Lcc_all)\n",
    "\n",
    "#The diameter is the maximum eccentricity -> longest shortest path in the network\n",
    "print(\"The diameter of the LCC is {0}.\".format(nx.diameter(G_lcc_all)))\n",
    "#The radius -> minimum eccentricity\n",
    "print(\"The radius of the LCC is {0}.\".format(nx.radius(G_lcc_all)))\n",
    "#print the node with eccentricity equals to the radius\n",
    "print(\"Candidate nodes in LCC can be used for adding edges with are {0}.\".format(nx.center(G_lcc_all)))\n",
    "\n",
    "#Add the edges for the whole network\n",
    "G_all_copy.add_edges_from([(32,229),(3,10),(105,1192),(308,1797),(456,1812)])\n",
    "\n",
    "#Compute the result\n",
    "print(\"Is it true that the network is connected?: {0}.\".format(nx.is_connected(G_all_copy)))\n",
    "#The diameter is the maximum eccentricity. -> longest shortest path in the network\n",
    "print(\"The diameter of the whole graph is {0}.\".format(nx.diameter(G_all_copy)))\n",
    "#The radius -> minimum eccentricity\n",
    "print(\"The radius of the whole graph is {0}.\".format(nx.radius(G_all_copy)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2218e169",
   "metadata": {},
   "source": [
    "ANSWER: Minimum five hypothetical edges should be added between node (32,229),(3,10),(105,1192),(308,1797),(456,1812) to make the whole network connected without increase the longest shortest path(diameter).\n",
    "\n",
    "- Explanation:\n",
    "    - 6 isolated connected components were found. Five of them should be connected to the largest connected component.\n",
    "    - The diameter for the LCC was computed to understand the current maximum eccentricity.\n",
    "    - The candidate nodes with eccentricity equals to the radius were found.\n",
    "    - Edges were then added between the candidate nodes and nodes need to be connected.\n",
    "- Justification:\n",
    "    - Minimum 5 edges are required to make the graph connected in this case.\n",
    "    - Nodes with eccentricity equals to the radius have the shortest path(4) to all other nodes.\n",
    "    - Add edges with them will have no impact on diameter.\n",
    "    - A potentially worse case is to add edges with \"the periphery\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa92191-51cc-4f9d-966c-b8cd5de3d80d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 2 of 2 \n",
    "\n",
    "Using the largest connected component of the network constructed from all data in Task 1, Q2, assume the role of an outsider with complete visibility of the network that now wishes to spread a hypothetical message such that everyone in the component would know the information it contained as quickly as possible. Assume that messages will now spread in sequential timesteps using the following mechanism. If an individual is told the message at timestep ùë°, the individual will forward the message to all of their direct connections at timestep ùë°+1. Individuals can therefore be told the message more than once. From this, answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e447d7-e1a4-40d7-a4af-a7e4f6c2a214",
   "metadata": {},
   "source": [
    "##### Q1. If you could only select 1 individual to tell at timestep 0, what set of nodes could you select from which would result in the message being received by everyone in the fewest timesteps as possible and what would the number of timesteps be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1299b7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least time step is 5\n",
      "[32, 34, 9, 52, 58, 12, 8, 72, 73, 88, 194, 209, 252, 254, 272, 297, 308, 309, 349, 365, 368, 372, 377, 394, 409, 448, 454, 475, 481, 482, 513, 527, 542, 586, 617, 638, 640, 652, 654, 673, 679, 681, 683, 686, 687, 697, 712, 711, 713, 753, 758, 823, 834, 986]\n"
     ]
    }
   ],
   "source": [
    "#CODE\n",
    "#prepare a list of nodes that will be used in for loop\n",
    "list_of_nodes = list(G_1st_28_days_lcc.nodes())\n",
    "num_of_nodes = G_1st_28_days_lcc.number_of_nodes()\n",
    "\n",
    "#create a function to build the Epidemic model\n",
    "def model_build(s_node,i_size):\n",
    "    #if the argument is int then convert it to list\n",
    "    if type(s_node) == int:\n",
    "        s_node = [s_node]\n",
    "    else:\n",
    "        s_node = s_node\n",
    "    #Using the largest connected component\n",
    "    model = ep.SIModel(G_1st_28_days_lcc)\n",
    "    model_configuration = mc.Configuration()\n",
    "    #set the model parameter 'beta' to 1 = (100%)\n",
    "    model_configuration.add_model_parameter('beta',1)\n",
    "    #set the initial configuration as per the given parameter\n",
    "    model_configuration.add_model_initial_configuration(\"Infected\",s_node)\n",
    "    #set the status\n",
    "    model.set_initial_status(model_configuration)\n",
    "    #given the i_size parameter, set the iteration size\n",
    "    iterations = model.iteration_bunch(bunch_size = i_size)\n",
    "    #get the trends result\n",
    "    trends = model.build_trends(iterations)\n",
    "    #get the least time step to reach the whole network\n",
    "    try:\n",
    "        least_timestep = (trends[0]['trends']['node_count'][1].index(num_of_nodes)) + 1\n",
    "    except:\n",
    "        least_timestep = np.nan\n",
    "    #get the result of the last iteration from the node_count result in trends\n",
    "    infected_result = trends[0]['trends']['node_count'][1][i_size-1]\n",
    "    return least_timestep, infected_result\n",
    "\n",
    "#append the timestep\n",
    "least_timestep_list = []\n",
    "\n",
    "#for loop each node\n",
    "for node in list_of_nodes:\n",
    "    # 10 is an arbitrary iteration number, if the min is equal to 10, iteration number should be adjusted to test.\n",
    "    x, _ = model_build(node,10)\n",
    "    least_timestep_list.append(x)\n",
    "\n",
    "#find the min\n",
    "min_least_timestep_list = min(least_timestep_list)\n",
    "\n",
    "#print the answer\n",
    "print(\"least time step is {0}\".format(min_least_timestep_list))\n",
    "      \n",
    "#create an empty list for holding the result\n",
    "result_list = []\n",
    "      \n",
    "#iterate through all nodes and append the result to the list\n",
    "for node in list_of_nodes:\n",
    "    #use the min_least_timestep_list to re-run the code\n",
    "    _, y = model_build(node, min_least_timestep_list)\n",
    "    result_list.append(y)\n",
    "\n",
    "#create a pandas dataframe to store the result\n",
    "df_result_t2q1 = pd.DataFrame({\"node_id\":list_of_nodes,\n",
    "                               \"number_of_nodes_infected\":result_list})\\\n",
    ".query(\"number_of_nodes_infected == @G_1st_28_days_lcc.number_of_nodes()\")\n",
    "\n",
    "#print the result\n",
    "print(df_result_t2q1['node_id'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56455101",
   "metadata": {},
   "source": [
    "ANSWER: The individual can be chosen from above list of nodes. The fewest timestep is 5 for the whole network to be infected for given nodes.\n",
    "- Explanation:\n",
    "    - SIModel was used to stimulate the spread of information.\n",
    "    - During 10 iterations, the minimum timestep (5) was found.\n",
    "    - The model was re-run using 5 as iteration to find all nodes that result in diffuse message in this fewest timesteps.\n",
    "- Justification:\n",
    "    - The model parameter 'beta' was set to 1. Because if someone was told the message, it is 100% that they have received/infected, assuming that the message platform is well functioning without loss of message during the process.\n",
    "    - 10 iterations is an arbitrary iteration number and should be adjust case by case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7161ea1f-f955-49fd-b612-64dfa50adf6e",
   "metadata": {},
   "source": [
    "##### Q2. If you had to select any 5 individuals to tell at timestep 0, can the message be received by everyone in fewer timesteps than the single individual selection in Q1? In determining your answer, use one or more appropriate network connectivity measures, rather than an exhaustive search through every combination of nodes in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf5a3d14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can timestep further reduced to 3 iterations?\n",
      "-----------------end of result------------------\n",
      "can timestep further reduced to 4 iterations?\n",
      "(32, 194, 103, 9, 638) 1144\n",
      "(32, 194, 41, 9, 638) 1144\n",
      "(32, 194, 9, 105, 638) 1144\n",
      "(32, 194, 9, 400, 638) 1144\n",
      "(32, 103, 41, 9, 638) 1144\n",
      "(32, 103, 9, 105, 638) 1144\n",
      "(32, 103, 9, 400, 638) 1144\n",
      "(32, 41, 9, 105, 638) 1144\n",
      "(32, 41, 9, 400, 638) 1144\n",
      "(32, 9, 105, 400, 638) 1144\n",
      "(194, 103, 41, 9, 638) 1144\n",
      "(194, 103, 9, 105, 638) 1144\n",
      "(194, 103, 9, 400, 638) 1144\n",
      "(194, 41, 9, 105, 638) 1144\n",
      "(194, 41, 9, 400, 638) 1144\n",
      "(194, 9, 105, 400, 638) 1144\n",
      "-----------------end of result------------------\n"
     ]
    }
   ],
   "source": [
    "#Code:\n",
    "#define the model\n",
    "def model_build_q2(s_node,i_size):\n",
    "    #if the argument is int then convert it to list\n",
    "    if type(s_node) == int:\n",
    "        s_node = [s_node]\n",
    "    else:\n",
    "        s_node = s_node\n",
    "    #Using the largest connected component\n",
    "    model = ep.SIModel(G_1st_28_days_lcc)\n",
    "    model_configuration = mc.Configuration()\n",
    "    #set the model parameter 'beta' to 1 = (100%)\n",
    "    model_configuration.add_model_parameter('beta',1)\n",
    "    #set the initial configuration as per the given parameter\n",
    "    model_configuration.add_model_initial_configuration(\"Infected\",s_node)\n",
    "    #set the status\n",
    "    model.set_initial_status(model_configuration)\n",
    "    #given the i_size parameter, set the iteration size\n",
    "    iterations = model.iteration_bunch(bunch_size = i_size)\n",
    "    #get the trends result\n",
    "    trends = model.build_trends(iterations)\n",
    "    #get the result of the last iteration from the node_count result in trends\n",
    "    infected_result = trends[0]['trends']['node_count'][1][i_size-1]\n",
    "    return infected_result\n",
    "\n",
    "#how many nodes?\n",
    "k = 5\n",
    "\n",
    "def sort_result(x):\n",
    "    result = sorted(\n",
    "        [(node[0],node[1]) for node in dict(x).items()],\n",
    "        key=operator.itemgetter(1),\n",
    "        reverse=True)\n",
    "    return [node for (node,value) in result[:k]]\n",
    "\n",
    "#find top 5 nodes with highest degree\n",
    "candidates_degree = sort_result(nx.degree(G_1st_28_days_lcc))\n",
    "\n",
    "#find top 5 nodes with highest pagerank\n",
    "candidates_pagerank_centrality = sort_result(nx.pagerank(G_1st_28_days_lcc))\n",
    "\n",
    "#find top 5 nodes with highest eigenvector\n",
    "candidates_eigenvector = sort_result(nx.eigenvector_centrality(G_1st_28_days_lcc))\n",
    "\n",
    "#find top 5 nodes with highest betweenness\n",
    "candidates_betweenness = sort_result(nx.betweenness_centrality(G_1st_28_days_lcc))\n",
    "\n",
    "#find top 5 nodes with highest closeness\n",
    "candidates_closeness_centrality = sort_result(nx.closeness_centrality(G_1st_28_days_lcc))\n",
    "\n",
    "#find top 5 nodes with highest degree centrality\n",
    "candidates_degree_centrality = sort_result(nx.degree_centrality(G_1st_28_days_lcc))\n",
    "\n",
    "\n",
    "#combine all candiates into a set\n",
    "all_candidates = set(candidates_degree + \n",
    "                     candidates_pagerank_centrality + \n",
    "                     candidates_eigenvector + \n",
    "                     candidates_betweenness + \n",
    "                     candidates_closeness_centrality + \n",
    "                     candidates_degree_centrality)\n",
    "\n",
    "#create all possible candidates\n",
    "all_possible_candidates = list(combinations(all_candidates, 5))\n",
    "\n",
    "#for loop - can timestep further reduced to 3 iterations?\n",
    "print(\"can timestep further reduced to 3 iterations?\")\n",
    "for combination in all_possible_candidates:\n",
    "    if model_build_q2(combination,3) == G_1st_28_days_lcc.number_of_nodes():\n",
    "        print(combination, model_build_q2(combination,3))\n",
    "    else:\n",
    "        continue\n",
    "print(\"-----------------end of result------------------\")        \n",
    "print(\"can timestep further reduced to 4 iterations?\")\n",
    "#for loop - can timestep further reduced to 4 iterations?\n",
    "for combination in all_possible_candidates:\n",
    "    if model_build_q2(combination,4) == G_1st_28_days_lcc.number_of_nodes():\n",
    "        print(combination, model_build_q2(combination,4))\n",
    "    else:\n",
    "        continue\n",
    "print(\"-----------------end of result------------------\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faef6cfc",
   "metadata": {},
   "source": [
    "ANSWER: By choosing 5 individuals to tell at timestep 0, the timestep can be further reduced to 4 iterations.\n",
    "- Explanation:\n",
    "    - The model used here for stimulation was same to Q1.\n",
    "    - Candidates were generated using measures(non-exhaustive) considering the different roles they play in a network.\n",
    "    - All combinations include 5 individuals were generated from the candidates set.\n",
    "    - Using iteration batch size(3/4), it was found that timestep can be further reduced to 4.\n",
    "- Justification:\n",
    "    - Nodes with high degree centrality, Pagerank centrality, eigenvector centrality, betweenness centrality, or closeness centrality can be good candidates for the analysis, as each centrality measure captures a different aspect of a node's importance within the network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
